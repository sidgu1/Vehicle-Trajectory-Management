{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eNJOcQFoVI8m"
   },
   "outputs": [],
   "source": [
    "# UTILS\n",
    "from __future__ import print_function, division\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as scp\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "\n",
    "# Dataset class for the NGSIM dataset\n",
    "class ngsimDataset(Dataset):\n",
    "    def __init__(self, mat_file, t_h=30, t_f=10, d_s=2, enc_size = 64, grid_size = (13,3)):\n",
    "        self.D = scp.loadmat(mat_file)['traj']\n",
    "        self.T = scp.loadmat(mat_file)['tracks']\n",
    "        self.t_h = t_h\n",
    "        self.t_f = t_f\n",
    "        self.d_s = d_s\n",
    "        self.enc_size = enc_size\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.D)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        dsId = self.D[idx, 0].astype(int)\n",
    "        vehId = self.D[idx, 1].astype(int)\n",
    "        t = self.D[idx, 2]\n",
    "        grid = self.D[idx,8:]\n",
    "        neighbors = []\n",
    "        hist = self.getHistory(vehId,t,vehId,dsId)\n",
    "        fut = self.getFuture(vehId,t,dsId)\n",
    "        for i in grid:\n",
    "            neighbors.append(self.getHistory(i.astype(int), t,vehId,dsId))\n",
    "        lon_enc = np.zeros([2])\n",
    "        lon_enc[int(self.D[idx, 7] - 1)] = 1\n",
    "        lat_enc = np.zeros([3])\n",
    "        lat_enc[int(self.D[idx, 6] - 1)] = 1\n",
    "        return hist,fut,neighbors,lat_enc,lon_enc, vehId, t, dsId\n",
    "\n",
    "    def getHistory(self,vehId,t,refVehId,dsId):\n",
    "        if vehId == 0:\n",
    "            return np.empty([0,2])\n",
    "        else:\n",
    "            if self.T.shape[1]<=vehId-1:\n",
    "                return np.empty([0,2])\n",
    "            refTrack = self.T[dsId-1][refVehId-1].transpose()\n",
    "            vehTrack = self.T[dsId-1][vehId-1].transpose()\n",
    "            refPos = refTrack[np.where(refTrack[:,0]==t)][0,1:3]\n",
    "            if vehTrack.size==0 or np.argwhere(vehTrack[:, 0] == t).size==0:\n",
    "                 return np.empty([0,2])\n",
    "            else:\n",
    "                stpt = np.maximum(0, np.argwhere(vehTrack[:, 0] == t).item() - self.t_h)\n",
    "                enpt = np.argwhere(vehTrack[:, 0] == t).item() + 1\n",
    "                hist = vehTrack[stpt:enpt:self.d_s,1:3]-refPos\n",
    "            if len(hist) < self.t_h//self.d_s + 1:\n",
    "                return np.empty([0,2])\n",
    "            return hist\n",
    "\n",
    "    def getFuture(self, vehId, t,dsId):\n",
    "        vehTrack = self.T[dsId-1][vehId-1].transpose()\n",
    "        refPos = vehTrack[np.where(vehTrack[:, 0] == t)][0, 1:3]\n",
    "        stpt = np.argwhere(vehTrack[:, 0] == t).item() + self.d_s\n",
    "        enpt = np.minimum(len(vehTrack), np.argwhere(vehTrack[:, 0] == t).item() + self.t_f + 1)\n",
    "        fut = vehTrack[stpt:enpt:self.d_s,1:3]-refPos\n",
    "        return fut\n",
    "\n",
    "    def collate_fn(self, samples):\n",
    "        nbr_batch_size = 0\n",
    "        for _,_,nbrs,_,_,_,_,_ in samples:\n",
    "            nbr_batch_size += sum([len(nbrs[i])!=0 for i in range(len(nbrs))])\n",
    "        maxlen = self.t_h//self.d_s + 1\n",
    "        if nbr_batch_size != 0:\n",
    "            nbrs_batch = torch.zeros(maxlen,nbr_batch_size,2)\n",
    "            pos = [0, 0]\n",
    "            mask_batch = torch.zeros(len(samples), self.grid_size[1],self.grid_size[0],self.enc_size)\n",
    "            mask_batch = mask_batch.byte()\n",
    "            hist_batch = torch.zeros(maxlen,len(samples),2)\n",
    "            fut_batch = torch.zeros(self.t_f//self.d_s,len(samples),2)\n",
    "            op_mask_batch = torch.zeros(self.t_f//self.d_s,len(samples),2)\n",
    "            lat_enc_batch = torch.zeros(len(samples),3)\n",
    "            lon_enc_batch = torch.zeros(len(samples), 2)\n",
    "            count = 0\n",
    "            veh_ID = []\n",
    "            time = []\n",
    "            dsID = []\n",
    "            for sampleId,(hist, fut, nbrs, lat_enc, lon_enc, vehId, t, ds) in enumerate(samples):\n",
    "                hist_batch[0:len(hist),sampleId,0] = torch.from_numpy(hist[:, 0])\n",
    "                hist_batch[0:len(hist), sampleId, 1] = torch.from_numpy(hist[:, 1])\n",
    "                fut_batch[0:len(fut), sampleId, 0] = torch.from_numpy(fut[:, 0])\n",
    "                fut_batch[0:len(fut), sampleId, 1] = torch.from_numpy(fut[:, 1])\n",
    "                op_mask_batch[0:len(fut),sampleId,:] = 1\n",
    "                lat_enc_batch[sampleId,:] = torch.from_numpy(lat_enc)\n",
    "                lon_enc_batch[sampleId, :] = torch.from_numpy(lon_enc)\n",
    "                veh_ID.append(vehId)\n",
    "                time.append(t)\n",
    "                dsID.append(ds)\n",
    "                for id,nbr in enumerate(nbrs):\n",
    "                    if len(nbr)!=0:\n",
    "                        nbrs_batch[0:len(nbr),count,0] = torch.from_numpy(nbr[:, 0])\n",
    "                        nbrs_batch[0:len(nbr), count, 1] = torch.from_numpy(nbr[:, 1])\n",
    "                        pos[0] = id % self.grid_size[0]\n",
    "                        pos[1] = id // self.grid_size[0]\n",
    "                        mask_batch[sampleId,pos[1],pos[0],:] = torch.ones(self.enc_size).byte()\n",
    "                        count+=1\n",
    "            return hist_batch, nbrs_batch, mask_batch, lat_enc_batch, lon_enc_batch, fut_batch, op_mask_batch, veh_ID, time, dsID\n",
    "        else:\n",
    "            return [-1], -1, -1, -1, -1, -1, -1, -1, -1, -1\n",
    "\n",
    "def outputActivation(x):\n",
    "    muX = x[:,:,0:1]\n",
    "    muY = x[:,:,1:2]\n",
    "\n",
    "    out = torch.cat([muX, muY],dim=2)\n",
    "    return out\n",
    "\n",
    "def maskedMSE(y_pred, y_gt, mask):\n",
    "    acc = torch.zeros_like(mask)\n",
    "    muX = y_pred[:,:,0]\n",
    "    muY = y_pred[:,:,1]\n",
    "    x = y_gt[:,:, 0]\n",
    "    y = y_gt[:,:, 1]\n",
    "    out = torch.pow(x-muX, 2) + torch.pow(y-muY, 2)\n",
    "    acc[:,:,0] = out\n",
    "    acc[:,:,1] = out\n",
    "    acc = acc*mask\n",
    "    lossVal = torch.sum(acc)/torch.sum(mask)\n",
    "    return lossVal\n",
    "\n",
    "def maskedMSETest(y_pred, y_gt, mask):\n",
    "    acc = torch.zeros_like(mask)\n",
    "    muX = y_pred[:, :, 0]\n",
    "    muY = y_pred[:, :, 1]\n",
    "    x = y_gt[:, :, 0]\n",
    "    y = y_gt[:, :, 1]\n",
    "    out = torch.pow(x - muX, 2) + torch.pow(y - muY, 2)\n",
    "    acc[:, :, 0] = out\n",
    "    acc[:, :, 1] = out\n",
    "    acc = acc * mask\n",
    "    lossVal = torch.sum(acc[:,:,0],dim=1)\n",
    "    counts = torch.sum(mask[:,:,0],dim=1)\n",
    "    return lossVal, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKj2bQcQVZYG"
   },
   "outputs": [],
   "source": [
    "# MODEL\n",
    "from __future__ import division\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class highwayNet(nn.Module):\n",
    "\n",
    "    ## Initialization\n",
    "    def __init__(self,args):\n",
    "        super(highwayNet, self).__init__()\n",
    "        self.args = args\n",
    "        self.use_cuda = args['use_cuda']\n",
    "        self.train_flag = args['train_flag']\n",
    "        self.encoder_size = args['encoder_size']\n",
    "        self.decoder_size = args['decoder_size']\n",
    "        self.in_length = args['in_length']\n",
    "        self.out_length = args['out_length']\n",
    "        self.grid_size = args['grid_size']\n",
    "        self.input_embedding_size = args['input_embedding_size']\n",
    "        # Input embedding layer\n",
    "        self.ip_emb = torch.nn.Linear(2,self.input_embedding_size)\n",
    "        # Encoder LSTM\n",
    "        self.enc_lstm1 = torch.nn.LSTM(self.input_embedding_size,self.encoder_size,1)\n",
    "        # Encoder LSTM\n",
    "        self.enc_lstm2 = torch.nn.LSTM(self.input_embedding_size,self.encoder_size,1)\n",
    "        self.spatial_embedding = nn.Linear(5, self.encoder_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.pre4att = nn.Sequential(\n",
    "            nn.Linear(self.encoder_size, 1),\n",
    "        )\n",
    "        self.dec_lstm = torch.nn.LSTM(self.encoder_size, self.decoder_size)\n",
    "        # Output layers:\n",
    "        self.op = torch.nn.Linear(self.decoder_size,2) # 2-dimension (x, y)\n",
    "        # Activations:\n",
    "        self.leaky_relu = torch.nn.LeakyReLU(0.1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def attention(self, lstm_out_weight, lstm_out):\n",
    "        alpha = F.softmax(lstm_out_weight, 1)\n",
    "        lstm_out = lstm_out.permute(0, 2, 1)\n",
    "        new_hidden_state = torch.bmm(lstm_out, alpha).squeeze(2)\n",
    "        new_hidden_state = F.relu(new_hidden_state)\n",
    "        return new_hidden_state, alpha\n",
    "\n",
    "    ## Forward Pass\n",
    "    def forward(self,hist,nbrs,masks,lat_enc,lon_enc):\n",
    "        lstm_out,(hist_enc,_) = self.enc_lstm1(self.leaky_relu(self.ip_emb(hist)))\n",
    "        lstm_out = lstm_out.permute(1, 0, 2)\n",
    "        lstm_weight = self.pre4att(self.tanh(lstm_out))\n",
    "        new_hidden, soft_attn_weights = self.attention(lstm_weight, lstm_out)\n",
    "        new_hidden = new_hidden.unsqueeze(2)\n",
    "        nbrs_out, (nbrs_enc,_) = self.enc_lstm1(self.leaky_relu(self.ip_emb(nbrs)))\n",
    "        nbrs_out = nbrs_out.permute(1, 0, 2)\n",
    "        nbrs_lstm_weight = self.pre4att(self.tanh(nbrs_out))\n",
    "        new_nbrs_hidden, soft_nbrs_attn_weights = self.attention(nbrs_lstm_weight, nbrs_out)\n",
    "        nbrs_enc = new_nbrs_hidden\n",
    "\n",
    "        soc_enc = torch.zeros_like(masks).float()\n",
    "        masks_tem = masks.permute(0, 3, 2, 1)\n",
    "        soc_enc = soc_enc.permute(0,3,2,1)\n",
    "        soc_enc = soc_enc.contiguous().view(soc_enc.shape[0], soc_enc.shape[1], -1)\n",
    "        new_hs = torch.cat((soc_enc, new_hidden), 2)\n",
    "        new_hs_per = new_hs.permute(0, 2, 1)\n",
    "\n",
    "        # second attention\n",
    "        weight = self.pre4att(self.tanh(new_hs_per))\n",
    "        new_hidden_ha, soft_attn_weights_ha = self.attention(weight, new_hs_per)\n",
    "        ## Concatenate encodings:\n",
    "        enc = new_hidden_ha\n",
    "        fut_pred = self.decode(enc)\n",
    "        return fut_pred, soft_attn_weights, soft_nbrs_attn_weights, soft_attn_weights_ha\n",
    "\n",
    "    def decode(self,enc):\n",
    "        enc = enc.repeat(self.out_length, 1, 1)\n",
    "        h_dec, _ = self.dec_lstm(enc)\n",
    "        h_dec = h_dec.permute(1, 0, 2)\n",
    "        fut_pred = self.op(h_dec)\n",
    "        fut_pred = fut_pred.permute(1, 0, 2)\n",
    "        fut_pred = outputActivation(fut_pred)\n",
    "        return fut_pred\n",
    "\n",
    "    def decode_by_step(self,enc):\n",
    "        pre_traj = []\n",
    "        decoder_input = enc\n",
    "        for _ in range(self.out_length):\n",
    "            decoder_input = decoder_input.unsqueeze(0)\n",
    "            h_dec, _ = self.dec_lstm(decoder_input)\n",
    "            h_for_pred = h_dec.squeeze()\n",
    "            fut_pred = self.op(h_for_pred)\n",
    "            pre_traj.append(fut_pred.view(fut_pred.size()[0], -1))\n",
    "            embedding_input = fut_pred\n",
    "            decoder_input = self.spatial_embedding(embedding_input)\n",
    "        pre_traj = torch.stack(pre_traj, dim=0)\n",
    "        pre_traj = outputActivation(pre_traj)\n",
    "        return pre_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DATABUanV2v-",
    "outputId": "9f4b2f44-dd2e-4a03-f579-6b05abe92a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "y35ToQjWVcMp",
    "outputId": "3529c488-dcae-4074-b512-966f7ced6d9c"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = {}\n",
    "    args['use_cuda'] = True\n",
    "    args['encoder_size'] = 64 # lstm encoder hidden state size, adjustable\n",
    "    args['decoder_size'] = 128 # lstm decoder hidden state size, adjustable\n",
    "    args['in_length'] = 16\n",
    "    args['out_length'] = 5\n",
    "    args['grid_size'] = (13,3)\n",
    "\n",
    "    args['input_embedding_size'] = 32 # input dimension for lstm encoder, adjustable\n",
    "\n",
    "    args['train_flag'] = True\n",
    "    start_time = datetime.datetime.now()\n",
    "    net = highwayNet(args)\n",
    "    if args['use_cuda']:\n",
    "        net = net.cuda()\n",
    "    trainEpochs = 1\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    batch_size = 128\n",
    "    crossEnt = torch.nn.BCELoss()\n",
    "    trSet = ngsimDataset('/content/drive/MyDrive/Trajectory_Datasets/TrainSet.mat')\n",
    "    valSet = ngsimDataset('/content/drive/MyDrive/Trajectory_Datasets/ValSet.mat')\n",
    "    trDataloader = DataLoader(trSet,batch_size=batch_size,shuffle=True,num_workers=2,collate_fn=trSet.collate_fn)\n",
    "    valDataloader = DataLoader(valSet,batch_size=batch_size,shuffle=True,num_workers=2,collate_fn=valSet.collate_fn)\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    prev_val_loss = math.inf\n",
    "\n",
    "    for epoch_num in range(trainEpochs):\n",
    "        net.train_flag = True\n",
    "        avg_tr_loss = 0\n",
    "        avg_tr_time = 0\n",
    "        avg_lat_acc = 0\n",
    "        avg_lon_acc = 0\n",
    "        for i, data in enumerate(trDataloader):\n",
    "            st_time = time.time()\n",
    "            hist, nbrs, mask, lat_enc, lon_enc, fut, op_mask, vehid, t, ds = data\n",
    "            if args['use_cuda']:\n",
    "                hist = hist.cuda()\n",
    "                nbrs = nbrs.cuda()\n",
    "                mask = mask.cuda()\n",
    "                lat_enc = lat_enc.cuda()\n",
    "                lon_enc = lon_enc.cuda()\n",
    "                fut = fut.cuda()\n",
    "                op_mask = op_mask.cuda()\n",
    "            fut_pred, weight_ts_center, weight_ts_nbr, weight_ha = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
    "            l = maskedMSE(fut_pred, fut, op_mask)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            a = torch.nn.utils.clip_grad_norm_(net.parameters(), 10)\n",
    "            optimizer.step()\n",
    "            batch_time = time.time()-st_time\n",
    "            avg_tr_loss += l.item()\n",
    "            avg_tr_time += batch_time\n",
    "            if i%100 == 99:\n",
    "                eta = avg_tr_time/100*(len(trSet)/batch_size-i)\n",
    "                print(\"Epoch no:\",epoch_num+1,\"| Epoch progress(%):\",format(i/(len(trSet)/batch_size)*100,'0.2f'), \"| Avg train loss:\",format(avg_tr_loss/100,'0.4f'),\"| Acc:\",format(avg_lat_acc,'0.4f'),format(avg_lon_acc,'0.4f'), \"| Validation loss prev epoch\",format(prev_val_loss,'0.4f'), \"| ETA(s):\",int(eta))\n",
    "                train_loss.append(avg_tr_loss/100)\n",
    "                avg_tr_loss = 0\n",
    "                avg_lat_acc = 0\n",
    "                avg_lon_acc = 0\n",
    "                avg_tr_time = 0\n",
    "        net.train_flag = False\n",
    "        print(\"Epoch\",epoch_num+1,'complete. Calculating validation loss...')\n",
    "        avg_val_loss = 0\n",
    "        avg_val_lat_acc = 0\n",
    "        avg_val_lon_acc = 0\n",
    "        val_batch_count = 0\n",
    "        total_points = 0\n",
    "\n",
    "        for i, data  in enumerate(valDataloader):\n",
    "            st_time = time.time()\n",
    "            hist, nbrs, mask, lat_enc, lon_enc, fut, op_mask, vehid, t, ds = data\n",
    "            if args['use_cuda']:\n",
    "                hist = hist.cuda()\n",
    "                nbrs = nbrs.cuda()\n",
    "                mask = mask.cuda()\n",
    "                lat_enc = lat_enc.cuda()\n",
    "                lon_enc = lon_enc.cuda()\n",
    "                fut = fut.cuda()\n",
    "                op_mask = op_mask.cuda()\n",
    "            fut_pred, weight_ts_center, weight_ts_nbr, weight_ha = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
    "            l = maskedMSE(fut_pred, fut, op_mask)\n",
    "            avg_val_loss += l.item()\n",
    "            val_batch_count += 1\n",
    "\n",
    "        print(avg_val_loss/val_batch_count)\n",
    "        print('Validation loss :',format(avg_val_loss/val_batch_count,'0.4f'))\n",
    "        val_loss.append(avg_val_loss/val_batch_count)\n",
    "        prev_val_loss = avg_val_loss/val_batch_count\n",
    "    end_time = datetime.datetime.now()\n",
    "    print('Total training time: ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HlXGUCNVxlt"
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '/LSTM.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFkiGCFYVeNV",
    "outputId": "d2f6497c-3fac-4541-ecd5-4354e84dcd23"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "args = {}\n",
    "args['use_cuda'] = True\n",
    "args['encoder_size'] = 64\n",
    "args['decoder_size'] = 128\n",
    "args['in_length'] = 16\n",
    "args['out_length'] = 5\n",
    "args['grid_size'] = (13,3)\n",
    "args['input_embedding_size'] = 32\n",
    "args['train_flag'] = False\n",
    "\n",
    "\n",
    "metric = 'rmse'\n",
    "net = highwayNet(args)\n",
    "net.load_state_dict(torch.load('/LSTM.tar'))\n",
    "if args['use_cuda']:\n",
    "    net = net.cuda()\n",
    "tsSet = ngsimDataset('/content/drive/MyDrive/Trajectory_Datasets/TestSet.mat')\n",
    "tsDataloader = DataLoader(tsSet,batch_size=128,shuffle=True,num_workers=2,collate_fn=tsSet.collate_fn)\n",
    "lossVals = torch.zeros(5).cuda()\n",
    "counts = torch.zeros(5).cuda()\n",
    "lossVal = 0\n",
    "count = 0\n",
    "vehid = []\n",
    "pred_x = []\n",
    "pred_y = []\n",
    "T = []\n",
    "dsID = []\n",
    "ts_cen = []\n",
    "ts_nbr = []\n",
    "wt_ha = []\n",
    "\n",
    "for i, data in enumerate(tsDataloader):\n",
    "    st_time = time.time()\n",
    "    hist, nbrs, mask, lat_enc, lon_enc, fut, op_mask, veh_id, t, ds = data\n",
    "    if not isinstance(hist, list):\n",
    "        vehid.append(veh_id)\n",
    "        T.append(t)\n",
    "        dsID.append(ds)\n",
    "        if args['use_cuda']:\n",
    "            hist = hist.cuda()\n",
    "            nbrs = nbrs.cuda()\n",
    "            mask = mask.cuda()\n",
    "            lat_enc = lat_enc.cuda()\n",
    "            lon_enc = lon_enc.cuda()\n",
    "            fut = fut.cuda()\n",
    "            op_mask = op_mask.cuda()\n",
    "        fut_pred, weight_ts_center, weight_ts_nbr, weight_ha= net(hist, nbrs, mask, lat_enc, lon_enc)\n",
    "        l, c = maskedMSETest(fut_pred, fut, op_mask)\n",
    "        fut_pred_x = fut_pred[:,:,0].detach()\n",
    "        fut_pred_x = fut_pred_x.cpu().numpy()\n",
    "        fut_pred_y = fut_pred[:,:,1].detach()\n",
    "        fut_pred_y = fut_pred_y.cpu().numpy()\n",
    "        pred_x.append(fut_pred_x)\n",
    "        pred_y.append(fut_pred_y)\n",
    "        ts_cen.append(weight_ts_center[:, :, 0].detach().cpu().numpy())\n",
    "        ts_nbr.append(weight_ts_nbr[:, :, 0].detach().cpu().numpy())\n",
    "        wt_ha.append(weight_ha[:, :, 0].detach().cpu().numpy())\n",
    "        lossVal +=l.detach()\n",
    "        count += c.detach()\n",
    "\n",
    "print ('lossVal is:', lossVal)\n",
    "print(torch.pow(lossVal / count,0.5)*0.3048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgRJUjoW2gIi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
